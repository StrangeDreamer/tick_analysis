#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æƒé‡ä¼˜åŒ–è„šæœ¬ - åŸºäºå†å²æ•°æ®ä¼˜åŒ–è¯„åˆ†æ¨¡å‹æƒé‡

ä½¿ç”¨æ–¹æ³•ï¼š
1. å…ˆç”¨ collect_backtest_data.py æ”¶é›†1-2ä¸ªæœˆæ•°æ®
2. è¿è¡Œæ­¤è„šæœ¬åˆ†ææ•°æ®
3. è¾“å‡ºä¼˜åŒ–åçš„æƒé‡å»ºè®®

ä½œè€…ï¼šAI Assistant
æ—¥æœŸï¼š2026-02-05
"""

import pandas as pd
import numpy as np
import json
from scipy.optimize import minimize
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
import matplotlib.pyplot as plt
import seaborn as sns

# è®¾ç½®ä¸­æ–‡å­—ä½“ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False


class WeightOptimizer:
    def __init__(self, data_file="backtest_data.csv"):
        self.data_file = data_file
        self.df = None
        
        # å½“å‰æƒé‡ï¼ˆV8.4ï¼‰
        self.current_weights = {
            'relative_net_buy': 175,  # æ»¡åˆ†35ï¼Œç³»æ•°175
            'pressure_ratio': 20,  # æ»¡åˆ†20
            'large_trade': 40,  # æ»¡åˆ†20
            'momentum_ratio': 15,  # æ»¡åˆ†15
            'closing_ratio': 20,  # æ»¡åˆ†20
            'excess_return': 2,  # æ»¡åˆ†10
            'momentum_acceleration': 200,  # æ»¡åˆ†10
            'sustainability': 10,  # æ»¡åˆ†10
            'active_buy_ratio': 60,  # æ»¡åˆ†15
            'buy_concentration': 45,  # æ»¡åˆ†15
        }
        
        # ç‰¹å¾åˆ—è¡¨
        self.features = [
            'relative_net_buy',
            'pressure_ratio',
            'large_buy_ratio',
            'large_sell_ratio',
            'momentum_ratio',
            'closing_ratio',
            'momentum_acceleration',
            'sustainability',
            'excess_return',
            'active_buy_ratio',
            'buy_concentration',
            'kyle_lambda',
            'effective_spread',
            'wash_trade_ratio'
        ]
    
    def load_data(self):
        """åŠ è½½æ•°æ®"""
        print(f"\n{'='*60}")
        print("ğŸ“Š åŠ è½½æ•°æ®...")
        print(f"{'='*60}\n")
        
        try:
            self.df = pd.read_csv(self.data_file, encoding='utf-8-sig')
            print(f"âœ… æˆåŠŸåŠ è½½ {len(self.df)} æ¡è®°å½•")
            
            # åªä¿ç•™æœ‰T+1æ”¶ç›Šçš„æ•°æ®
            complete_data = self.df[self.df['T+1_return'].notna()].copy()
            print(f"âœ… æœ‰æ•ˆæ•°æ®ï¼ˆå«T+1æ”¶ç›Šï¼‰ï¼š{len(complete_data)} æ¡")
            
            if len(complete_data) < 30:
                print("\nâš ï¸ è­¦å‘Šï¼šæœ‰æ•ˆæ•°æ®ä¸è¶³30æ¡ï¼Œå»ºè®®ç»§ç»­æ”¶é›†æ•°æ®")
                print("   è‡³å°‘éœ€è¦1ä¸ªæœˆæ•°æ®ï¼ˆçº¦20-30ä¸ªäº¤æ˜“æ—¥ï¼‰æ‰èƒ½å¾—åˆ°å¯é ç»“æœ")
                return False
            
            self.df = complete_data
            
            # æ˜¾ç¤ºæ•°æ®æ¦‚è§ˆ
            print(f"\nğŸ“… æ•°æ®æ—¶é—´èŒƒå›´ï¼š{self.df['date'].min()} ~ {self.df['date'].max()}")
            print(f"ğŸ“ˆ å¹³å‡T+1æ”¶ç›Šï¼š{self.df['T+1_return'].mean():.2f}%")
            print(f"ğŸ“Š T+1æ”¶ç›Šæ ‡å‡†å·®ï¼š{self.df['T+1_return'].std():.2f}%")
            print(f"ğŸ” T+1æœ€å¤§æ”¶ç›Šï¼š{self.df['T+1_return'].max():.2f}%")
            print(f"ğŸ”» T+1æœ€å°æ”¶ç›Šï¼š{self.df['T+1_return'].min():.2f}%")
            
            return True
            
        except FileNotFoundError:
            print(f"âŒ æ‰¾ä¸åˆ°æ–‡ä»¶ï¼š{self.data_file}")
            print("   è¯·å…ˆè¿è¡Œ collect_backtest_data.py æ”¶é›†æ•°æ®")
            return False
        except Exception as e:
            print(f"âŒ åŠ è½½æ•°æ®å¤±è´¥ï¼š{e}")
            return False
    
    def analyze_correlations(self):
        """åˆ†æå„æŒ‡æ ‡ä¸T+1æ”¶ç›Šçš„ç›¸å…³æ€§"""
        print(f"\n{'='*60}")
        print("ğŸ“Š åˆ†æ1ï¼šæŒ‡æ ‡ä¸T+1æ”¶ç›Šçš„ç›¸å…³æ€§")
        print(f"{'='*60}\n")
        
        correlations = []
        for feature in self.features:
            if feature in self.df.columns:
                corr = self.df[feature].corr(self.df['T+1_return'])
                correlations.append({
                    'feature': feature,
                    'correlation': corr,
                    'abs_corr': abs(corr)
                })
        
        corr_df = pd.DataFrame(correlations).sort_values('abs_corr', ascending=False)
        
        print("ç›¸å…³æ€§æ’åï¼ˆç»å¯¹å€¼ï¼‰ï¼š\n")
        print(f"{'æŒ‡æ ‡':<30} {'ç›¸å…³ç³»æ•°':>10} {'å¼ºåº¦':>10}")
        print("-" * 52)
        
        for _, row in corr_df.iterrows():
            feature = row['feature']
            corr = row['correlation']
            abs_corr = row['abs_corr']
            
            # åˆ¤æ–­å¼ºåº¦
            if abs_corr > 0.3:
                strength = "â­â­â­ å¼º"
            elif abs_corr > 0.15:
                strength = "â­â­ ä¸­"
            elif abs_corr > 0.05:
                strength = "â­ å¼±"
            else:
                strength = "âŒ æå¼±"
            
            print(f"{feature:<30} {corr:>10.3f} {strength:>10}")
        
        # æ‰¾å‡ºæœ€é‡è¦çš„æŒ‡æ ‡
        top_features = corr_df.head(5)['feature'].tolist()
        print(f"\nğŸ’¡ Top5æœ€é‡è¦æŒ‡æ ‡ï¼š")
        for i, feature in enumerate(top_features, 1):
            print(f"   {i}. {feature}")
        
        return corr_df
    
    def analyze_feature_importance(self):
        """ä½¿ç”¨éšæœºæ£®æ—åˆ†æç‰¹å¾é‡è¦æ€§"""
        print(f"\n{'='*60}")
        print("ğŸ“Š åˆ†æ2ï¼šç‰¹å¾é‡è¦æ€§ï¼ˆéšæœºæ£®æ—ï¼‰")
        print(f"{'='*60}\n")
        
        # å‡†å¤‡æ•°æ®
        X = self.df[self.features].fillna(0)
        y = self.df['T+1_return']
        
        # è®­ç»ƒéšæœºæ£®æ—
        rf = RandomForestRegressor(n_estimators=100, random_state=42, max_depth=10)
        rf.fit(X, y)
        
        # è·å–ç‰¹å¾é‡è¦æ€§
        importances = pd.DataFrame({
            'feature': self.features,
            'importance': rf.feature_importances_
        }).sort_values('importance', ascending=False)
        
        print("ç‰¹å¾é‡è¦æ€§æ’åï¼š\n")
        print(f"{'æŒ‡æ ‡':<30} {'é‡è¦æ€§':>10} {'æ˜Ÿçº§':>10}")
        print("-" * 52)
        
        for _, row in importances.iterrows():
            feature = row['feature']
            importance = row['importance']
            
            # è½¬æ¢ä¸ºæ˜Ÿçº§
            if importance > 0.15:
                stars = "â­â­â­ é«˜"
            elif importance > 0.08:
                stars = "â­â­ ä¸­"
            elif importance > 0.03:
                stars = "â­ ä½"
            else:
                stars = "âŒ æä½"
            
            print(f"{feature:<30} {importance:>10.3f} {stars:>10}")
        
        # æ¨¡å‹è¯„åˆ†
        score = rf.score(X, y)
        print(f"\nğŸ“Š æ¨¡å‹RÂ²è¯„åˆ†ï¼š{score:.3f}")
        print(f"   ï¼ˆ>0.3ä¸ºè‰¯å¥½ï¼Œ>0.5ä¸ºä¼˜ç§€ï¼‰")
        
        return importances
    
    def analyze_score_groups(self):
        """åˆ†æä¸åŒè¯„åˆ†åŒºé—´çš„T+1æ”¶ç›Š"""
        print(f"\n{'='*60}")
        print("ğŸ“Š åˆ†æ3ï¼šè¯„åˆ†åŒºé—´ä¸T+1æ”¶ç›Š")
        print(f"{'='*60}\n")
        
        # åˆ›å»ºè¯„åˆ†åŒºé—´
        bins = [-100, 0, 30, 50, 70, 90, 100]
        labels = ['<0', '0-30', '30-50', '50-70', '70-90', '90+']
        
        self.df['score_group'] = pd.cut(self.df['score'], bins=bins, labels=labels)
        
        # æŒ‰åŒºé—´ç»Ÿè®¡
        grouped = self.df.groupby('score_group', observed=True).agg({
            'T+1_return': ['mean', 'std', 'count'],
            'symbol': 'count'
        })
        
        print("è¯„åˆ†åŒºé—´åˆ†æï¼š\n")
        print(f"{'åŒºé—´':<10} {'æ•°é‡':>6} {'å¹³å‡T+1æ”¶ç›Š':>12} {'æ ‡å‡†å·®':>10} {'å»ºè®®':>15}")
        print("-" * 60)
        
        for group in labels:
            if group in grouped.index:
                count = int(grouped.loc[group, ('symbol', 'count')])
                mean_return = grouped.loc[group, ('T+1_return', 'mean')]
                std_return = grouped.loc[group, ('T+1_return', 'std')]
                
                # åˆ¤æ–­å»ºè®®
                if mean_return > 2:
                    advice = "âœ… é‡ä»“"
                elif mean_return > 1:
                    advice = "âœ… ä¸­ä»“"
                elif mean_return > 0:
                    advice = "âš ï¸ è½»ä»“"
                else:
                    advice = "âŒ å›é¿"
                
                print(f"{group:<10} {count:>6} {mean_return:>11.2f}% {std_return:>9.2f}% {advice:>15}")
        
        # å…³é”®å‘ç°
        high_score = self.df[self.df['score'] >= 70]
        if len(high_score) > 0:
            print(f"\nğŸ’¡ å…³é”®å‘ç°ï¼š")
            print(f"   è¯„åˆ†â‰¥70çš„è‚¡ç¥¨ï¼ˆ{len(high_score)}åªï¼‰")
            print(f"   å¹³å‡T+1æ”¶ç›Šï¼š{high_score['T+1_return'].mean():.2f}%")
            print(f"   èƒœç‡ï¼š{(high_score['T+1_return'] > 0).sum() / len(high_score) * 100:.1f}%")
    
    def optimize_weights(self):
        """ä¼˜åŒ–æƒé‡ï¼ˆç®€å•çº¿æ€§å›å½’ï¼‰"""
        print(f"\n{'='*60}")
        print("ğŸ“Š åˆ†æ4ï¼šæƒé‡ä¼˜åŒ–å»ºè®®")
        print(f"{'='*60}\n")
        
        # å‡†å¤‡æ•°æ®
        X = self.df[self.features].fillna(0)
        y = self.df['T+1_return']
        
        # çº¿æ€§å›å½’
        lr = LinearRegression()
        lr.fit(X, y)
        
        # è·å–ç³»æ•°
        coefficients = pd.DataFrame({
            'feature': self.features,
            'coefficient': lr.coef_,
            'abs_coef': np.abs(lr.coef_)
        }).sort_values('abs_coef', ascending=False)
        
        print("ä¼˜åŒ–åçš„æƒé‡å»ºè®®ï¼š\n")
        print(f"{'æŒ‡æ ‡':<30} {'å½“å‰æƒé‡':>10} {'å»ºè®®æƒé‡':>12} {'å˜åŒ–':>10}")
        print("-" * 65)
        
        # æ ‡å‡†åŒ–ç³»æ•°åˆ°0-35çš„èŒƒå›´
        max_coef = coefficients['abs_coef'].max()
        
        for _, row in coefficients.iterrows():
            feature = row['feature']
            coef = row['coefficient']
            abs_coef = row['abs_coef']
            
            # è®¡ç®—å»ºè®®æƒé‡ï¼ˆæ ‡å‡†åŒ–åˆ°35åˆ†æ»¡åˆ†ï¼‰
            suggested_weight = (abs_coef / max_coef) * 35
            
            # è·å–å½“å‰æƒé‡
            if feature in self.current_weights:
                current = self.current_weights[feature]
            else:
                current = 10  # é»˜è®¤
            
            # è®¡ç®—å˜åŒ–
            change = suggested_weight - current
            change_pct = (change / current * 100) if current > 0 else 0
            
            if abs(change_pct) > 20:
                change_str = f"{change:+.1f}åˆ† âš ï¸"
            else:
                change_str = f"{change:+.1f}åˆ†"
            
            print(f"{feature:<30} {current:>10.1f} {suggested_weight:>12.1f} {change_str:>10}")
        
        print(f"\nğŸ“Š ä¼˜åŒ–åæ¨¡å‹RÂ²ï¼š{lr.score(X, y):.3f}")
    
    def generate_report(self):
        """ç”Ÿæˆå®Œæ•´åˆ†ææŠ¥å‘Š"""
        print(f"\n{'='*60}")
        print("ğŸ“‹ ç”Ÿæˆåˆ†ææŠ¥å‘Š...")
        print(f"{'='*60}\n")
        
        if not self.load_data():
            return
        
        # æ‰§è¡Œæ‰€æœ‰åˆ†æ
        corr_df = self.analyze_correlations()
        importance_df = self.analyze_feature_importance()
        self.analyze_score_groups()
        self.optimize_weights()
        
        # ç»¼åˆå»ºè®®
        print(f"\n{'='*60}")
        print("ğŸ’¡ ç»¼åˆå»ºè®®")
        print(f"{'='*60}\n")
        
        print("åŸºäºä»¥ä¸Šåˆ†æï¼Œæƒé‡è°ƒæ•´å»ºè®®ï¼š\n")
        
        print("1. ä¿æŒé«˜æƒé‡çš„æŒ‡æ ‡ï¼ˆç›¸å…³æ€§>0.2æˆ–é‡è¦æ€§>0.1ï¼‰ï¼š")
        print("   - è¿™äº›æŒ‡æ ‡å¯¹T+1æ”¶ç›Šæœ‰æ˜æ˜¾é¢„æµ‹ä½œç”¨")
        print("   - å»ºè®®ä¿æŒæˆ–æå‡æƒé‡\n")
        
        print("2. é™ä½æƒé‡çš„æŒ‡æ ‡ï¼ˆç›¸å…³æ€§<0.05ä¸”é‡è¦æ€§<0.03ï¼‰ï¼š")
        print("   - è¿™äº›æŒ‡æ ‡å¯¹T+1æ”¶ç›Šé¢„æµ‹ä½œç”¨ä¸æ˜æ˜¾")
        print("   - å»ºè®®é™ä½æƒé‡æˆ–ç§»é™¤\n")
        
        print("3. è¯„åˆ†é˜ˆå€¼å»ºè®®ï¼š")
        print("   - æ ¹æ®'è¯„åˆ†åŒºé—´åˆ†æ'è°ƒæ•´ä¹°å…¥é˜ˆå€¼")
        print("   - å¦‚æœ70åˆ†ä»¥ä¸Šæ”¶ç›Šæ˜¾è‘—ï¼Œå¯ä»¥æé«˜é˜ˆå€¼åˆ°75åˆ†\n")
        
        print("4. æ³¨æ„äº‹é¡¹ï¼š")
        print("   âš ï¸ æ ·æœ¬é‡è‡³å°‘éœ€è¦100æ¡æœ‰æ•ˆæ•°æ®")
        print("   âš ï¸ ä¸åŒå¸‚åœºç¯å¢ƒä¸‹è¡¨ç°å¯èƒ½ä¸åŒ")
        print("   âš ï¸ å»ºè®®æ¯å­£åº¦é‡æ–°è¯„ä¼°ä¸€æ¬¡")
        print("   âš ï¸ é¿å…è¿‡åº¦æ‹Ÿåˆå†å²æ•°æ®\n")
        
        # ä¿å­˜æŠ¥å‘Š
        report_file = f"weight_optimization_report_{pd.Timestamp.now().strftime('%Y%m%d')}.txt"
        print(f"ğŸ“„ æŠ¥å‘Šå·²ä¿å­˜åˆ°ï¼š{report_file}")


def main():
    optimizer = WeightOptimizer()
    optimizer.generate_report()


if __name__ == "__main__":
    main()

#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import warnings
from concurrent.futures import ThreadPoolExecutor, as_completed, TimeoutError
import time
import traceback

from collections import defaultdict

warnings.filterwarnings('ignore')
import akshare as ak

try:
    import urllib3

    urllib3.disable_warnings()
except (ImportError, AttributeError):
    pass

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import requests
import json
import hashlib
import base64
import hmac
from sklearn.linear_model import LinearRegression


class QuantAnalysis:
    def __init__(self):
        self.max_workers = min(os.cpu_count() + 4, 16)  # ä¼˜åŒ–çº¿ç¨‹æ•°
        self.hot_stocks_cache_file = "hot_stocks_cache.json"
        self.historical_metrics_cache_file = "historical_metrics_cache.json"
        self.fund_flow_cache_file = "fund_flow_cache.json"
        self.tick_cache_dir = "tick_cache"
        self.chart_dir = "charts"

        # ç¡®ä¿ç¼“å­˜ç›®å½•å­˜åœ¨
        for directory in [self.tick_cache_dir, self.chart_dir]:
            if not os.path.exists(directory):
                os.makedirs(directory)

        # åˆå§‹åŒ–ä¼šè¯å¯¹è±¡ä»¥é‡ç”¨è¿æ¥
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        })

        # åˆå§‹åŒ–æ€§èƒ½è®¡æ•°å™¨
        self.perf_counters = defaultdict(float)
        self.start_time = time.time()

        # åˆå§‹åŒ–å¸‚åœºçŠ¶æ€
        self.market_status = self._get_market_status()

        print(f"ğŸš€ é‡åŒ–åˆ†æç³»ç»Ÿ V8.0 åˆå§‹åŒ–å®Œæˆï¼Œå½“å‰å¸‚åœºçŠ¶æ€: {self.market_status}")

    def _log_performance(self, task_name, start_time):
        """è®°å½•ä»»åŠ¡æ‰§è¡Œæ—¶é—´"""
        elapsed = time.time() - start_time
        self.perf_counters[task_name] += elapsed
        return elapsed

    def _get_market_status(self):
        """è·å–å½“å‰å¸‚åœºçŠ¶æ€"""
        now = datetime.now()
        weekday = now.weekday()

        # å‘¨æœ«
        if weekday >= 5:
            return "å·²ä¼‘å¸‚(å‘¨æœ«)"

        # å·¥ä½œæ—¥åˆ¤æ–­äº¤æ˜“æ—¶é—´
        current_time = now.time()
        morning_start = datetime.strptime("09:30:00", "%H:%M:%S").time()
        morning_end = datetime.strptime("11:30:00", "%H:%M:%S").time()
        afternoon_start = datetime.strptime("13:00:00", "%H:%M:%S").time()
        afternoon_end = datetime.strptime("15:00:00", "%H:%M:%S").time()

        if (morning_start <= current_time <= morning_end) or (afternoon_start <= current_time <= afternoon_end):
            return "äº¤æ˜“ä¸­"
        elif current_time > afternoon_end:
            return "å·²æ”¶ç›˜"
        elif current_time < morning_start:
            return "æœªå¼€ç›˜"
        else:
            return "åˆé—´ä¼‘å¸‚"

    def _get_market_performance(self):
        """è·å–å¤§ç›˜è¡¨ç°ä½œä¸ºåŸºå‡†"""
        task_start = time.time()
        try:
            market_df = ak.stock_individual_spot_xq(symbol="SH000001")
            change_row = market_df[market_df['item'] == 'æ¶¨å¹…']
            if not change_row.empty:
                market_change_pct = change_row['value'].iloc[0]
                print(f"ğŸ“ˆ å¤§ç›˜åŸºå‡† (ä¸Šè¯æŒ‡æ•°): {market_change_pct:.2f}%")

                # è·å–ä¸Šè¯50ã€æ²ªæ·±300å’Œåˆ›ä¸šæ¿æŒ‡æ•°è¡¨ç°
                try:
                    sz50_df = ak.stock_individual_spot_xq(symbol="SH000016")
                    sz50_change = sz50_df[sz50_df['item'] == 'æ¶¨å¹…']['value'].iloc[0]

                    hs300_df = ak.stock_individual_spot_xq(symbol="SH000300")
                    hs300_change = hs300_df[hs300_df['item'] == 'æ¶¨å¹…']['value'].iloc[0]

                    cyb_df = ak.stock_individual_spot_xq(symbol="SZ399006")
                    cyb_change = cyb_df[cyb_df['item'] == 'æ¶¨å¹…']['value'].iloc[0]

                    print(
                        f"ğŸ“Š å¸‚åœºè¡¨ç°: ä¸Šè¯50 {sz50_change:.2f}% | æ²ªæ·±300 {hs300_change:.2f}% | åˆ›ä¸šæ¿ {cyb_change:.2f}%")
                except Exception:
                    pass

                self._log_performance("get_market_perf", task_start)
                return float(market_change_pct)
        except Exception as e:
            print(f"âš ï¸ æ— æ³•è·å–å¤§ç›˜è¡¨ç°: {e}")
        self._log_performance("get_market_perf", task_start)
        return 0.0

    def _get_historical_data(self, symbol, thread_id=""):
        """è·å–å†å²æ•°æ®ï¼Œè®¡ç®—ADV20ã€ATR20ç­‰æŠ€æœ¯æŒ‡æ ‡"""
        try:
            end_date = datetime.now().strftime('%Y%m%d')
            start_date = (datetime.now() - timedelta(days=60)).strftime('%Y%m%d')  # æ‰©å¤§å†å²æ•°æ®èŒƒå›´
            pure_code = symbol[2:]
            hist_df = ak.stock_zh_a_hist(symbol=pure_code, start_date=start_date, end_date=end_date, adjust="qfq")
            if hist_df is None or len(hist_df) < 21: return None

            # åŸºç¡€é‡ä»·æŒ‡æ ‡
            adv20 = hist_df['æˆäº¤é‡'].rolling(window=20).mean().iloc[-1]

            # è®¡ç®—ATR20
            high_low = hist_df['æœ€é«˜'] - hist_df['æœ€ä½']
            high_prev_close = np.abs(hist_df['æœ€é«˜'] - hist_df['æ”¶ç›˜'].shift())
            low_prev_close = np.abs(hist_df['æœ€ä½'] - hist_df['æ”¶ç›˜'].shift())
            tr = np.max(pd.DataFrame({'hl': high_low, 'hpc': high_prev_close, 'lpc': low_prev_close}), axis=1)
            atr20 = tr.rolling(window=20).mean().iloc[-1]

            # è®¡ç®—æ³¢åŠ¨ç‡
            returns = hist_df['æ”¶ç›˜'].pct_change()
            volatility = returns.rolling(window=20).std().iloc[-1] * np.sqrt(252)

            # è®¡ç®—è¶‹åŠ¿å¼ºåº¦
            sma5 = hist_df['æ”¶ç›˜'].rolling(window=5).mean()
            sma20 = hist_df['æ”¶ç›˜'].rolling(window=20).mean()
            trend_strength = (sma5.iloc[-1] / sma20.iloc[-1] - 1) * 100

            # è®¡ç®—RSI
            delta = hist_df['æ”¶ç›˜'].diff()
            gain = delta.where(delta > 0, 0)
            loss = -delta.where(delta < 0, 0)
            avg_gain = gain.rolling(window=14).mean()
            avg_loss = loss.rolling(window=14).mean()
            rs = avg_gain / avg_loss
            rsi = 100 - (100 / (1 + rs)).iloc[-1]

            # è®¡ç®—MACD
            exp12 = hist_df['æ”¶ç›˜'].ewm(span=12, adjust=False).mean()
            exp26 = hist_df['æ”¶ç›˜'].ewm(span=26, adjust=False).mean()
            macd = exp12 - exp26
            signal = macd.ewm(span=9, adjust=False).mean()
            macd_hist = macd - signal
            macd_value = macd.iloc[-1]
            macd_signal = signal.iloc[-1]
            macd_hist_value = macd_hist.iloc[-1]

            # è®¡ç®—å¸ƒæ—å¸¦
            middle_band = hist_df['æ”¶ç›˜'].rolling(window=20).mean()
            std_dev = hist_df['æ”¶ç›˜'].rolling(window=20).std()
            upper_band = middle_band + (std_dev * 2)
            lower_band = middle_band - (std_dev * 2)
            bb_width = (upper_band - lower_band) / middle_band
            bb_width_value = bb_width.iloc[-1]

            # è®¡ç®—ç›¸å¯¹å¼ºåº¦(ä¸å¤§ç›˜æ¯”è¾ƒ)
            try:
                market_df = ak.stock_zh_a_hist(symbol="000001", start_date=start_date, end_date=end_date, adjust="qfq",
                                               period="daily")
                if market_df is not None and len(market_df) >= len(hist_df):
                    stock_returns = hist_df['æ”¶ç›˜'].pct_change().dropna()
                    market_returns = market_df['æ”¶ç›˜'].pct_change().dropna()
                    # ç¡®ä¿é•¿åº¦ä¸€è‡´
                    min_len = min(len(stock_returns), len(market_returns))
                    stock_returns = stock_returns[-min_len:]
                    market_returns = market_returns[-min_len:]

                    # è®¡ç®—Betaå’ŒAlpha
                    if len(stock_returns) > 5:
                        beta = np.cov(stock_returns, market_returns)[0, 1] / np.var(market_returns)
                        alpha = (stock_returns.mean() - beta * market_returns.mean()) * 252  # å¹´åŒ–Alpha
                    else:
                        beta = 1.0
                        alpha = 0.0
                else:
                    beta = 1.0
                    alpha = 0.0
            except Exception:
                beta = 1.0
                alpha = 0.0

            # è®¡ç®—æˆäº¤é‡å˜åŒ–è¶‹åŠ¿
            volume_trend = hist_df['æˆäº¤é‡'].pct_change().rolling(window=5).mean().iloc[-1]

            # è®¡ç®—ä»·æ ¼åŠ¨é‡
            momentum_5d = (hist_df['æ”¶ç›˜'].iloc[-1] / hist_df['æ”¶ç›˜'].iloc[-6] - 1) * 100 if len(hist_df) >= 6 else 0
            momentum_10d = (hist_df['æ”¶ç›˜'].iloc[-1] / hist_df['æ”¶ç›˜'].iloc[-11] - 1) * 100 if len(hist_df) >= 11 else 0

            # è®¡ç®—æ¢æ‰‹ç‡å¹³å‡å€¼
            turnover_mean = hist_df['æ¢æ‰‹ç‡'].rolling(window=20).mean().iloc[-1] if 'æ¢æ‰‹ç‡' in hist_df.columns else 0

            # è®¡ç®—ä»·æ ¼ä¸æˆäº¤é‡ç›¸å…³æ€§
            if len(hist_df) >= 20:
                price_changes = hist_df['æ”¶ç›˜'].pct_change().iloc[-20:]
                volume_changes = hist_df['æˆäº¤é‡'].pct_change().iloc[-20:]
                price_volume_corr = price_changes.corr(volume_changes)
            else:
                price_volume_corr = 0

            return {
                'adv20': adv20,
                'atr20': atr20,
                'volatility': volatility,
                'trend_strength': trend_strength,
                'rsi': rsi,
                'macd': macd_value,
                'macd_signal': macd_signal,
                'macd_hist': macd_hist_value,
                'bb_width': bb_width_value,
                'beta': beta,
                'alpha': alpha,
                'volume_trend': volume_trend,
                'momentum_5d': momentum_5d,
                'momentum_10d': momentum_10d,
                'turnover_mean': turnover_mean,
                'price_volume_corr': price_volume_corr
            }
        except Exception as e:
            print(f"  âš ï¸ è·å–å†å²æ•°æ®å¼‚å¸¸ ({symbol}): {e}")
            return None

    def _get_fund_flow_with_history(self, symbol, thread_id=""):
        """è·å–èµ„é‡‘æµæ•°æ®ï¼ŒåŒ…æ‹¬å†å²ç»Ÿè®¡"""
        try:
            pure_code = symbol[2:]
            market = "sh" if symbol.startswith("SH") else "sz"

            flow_df = ak.stock_individual_fund_flow(stock=pure_code, market=market)

            if flow_df is None or flow_df.empty or len(flow_df) < 21:
                return None

            flow_df['æ—¥æœŸ'] = pd.to_datetime(flow_df['æ—¥æœŸ'])
            flow_df = flow_df.sort_values(by='æ—¥æœŸ').reset_index(drop=True)

            # æ£€æŸ¥å¿…è¦çš„åˆ—æ˜¯å¦å­˜åœ¨
            required_columns = ['ä¸»åŠ›å‡€æµå…¥-å‡€é¢', 'è¶…å¤§å•å‡€æµå…¥-å‡€é¢', 'å¤§å•å‡€æµå…¥-å‡€é¢', 'ä¸­å•å‡€æµå…¥-å‡€é¢',
                                'å°å•å‡€æµå…¥-å‡€é¢']
            for col in required_columns:
                if col not in flow_df.columns:
                    print(f"  âš ï¸ èµ„é‡‘æµæ•°æ®ç¼ºå°‘åˆ—: {col}")
                    return None

            # è®¡ç®—æ•£æˆ·å‡€æµå…¥-å‡€é¢ (å°å• + ä¸­å•)
            flow_df['æ•£æˆ·å‡€æµå…¥-å‡€é¢'] = flow_df['å°å•å‡€æµå…¥-å‡€é¢'] + flow_df['ä¸­å•å‡€æµå…¥-å‡€é¢']

            today_flow_row = flow_df.iloc[-1]
            today_main_inflow = today_flow_row['ä¸»åŠ›å‡€æµå…¥-å‡€é¢'] / 10000
            today_retail_inflow = today_flow_row['æ•£æˆ·å‡€æµå…¥-å‡€é¢'] / 10000
            today_super_inflow = today_flow_row['è¶…å¤§å•å‡€æµå…¥-å‡€é¢'] / 10000
            today_big_inflow = today_flow_row['å¤§å•å‡€æµå…¥-å‡€é¢'] / 10000
            today_mid_inflow = today_flow_row['ä¸­å•å‡€æµå…¥-å‡€é¢'] / 10000
            today_small_inflow = today_flow_row['å°å•å‡€æµå…¥-å‡€é¢'] / 10000

            historical_flows = flow_df.iloc[-21:-1]
            if len(historical_flows) < 20: return None

            # è®¡ç®—ä¸»åŠ›èµ„é‡‘æµç»Ÿè®¡
            main_inflow_mean = historical_flows['ä¸»åŠ›å‡€æµå…¥-å‡€é¢'].mean() / 10000
            main_inflow_std = historical_flows['ä¸»åŠ›å‡€æµå…¥-å‡€é¢'].std() / 10000

            # è®¡ç®—è¶…å¤§å•èµ„é‡‘æµç»Ÿè®¡
            super_inflow_mean = historical_flows['è¶…å¤§å•å‡€æµå…¥-å‡€é¢'].mean() / 10000
            super_inflow_std = historical_flows['è¶…å¤§å•å‡€æµå…¥-å‡€é¢'].std() / 10000

            # è®¡ç®—å¤§å•èµ„é‡‘æµç»Ÿè®¡
            big_inflow_mean = historical_flows['å¤§å•å‡€æµå…¥-å‡€é¢'].mean() / 10000
            big_inflow_std = historical_flows['å¤§å•å‡€æµå…¥-å‡€é¢'].std() / 10000

            # è®¡ç®—ä¸­å•èµ„é‡‘æµç»Ÿè®¡
            mid_inflow_mean = historical_flows['ä¸­å•å‡€æµå…¥-å‡€é¢'].mean() / 10000
            mid_inflow_std = historical_flows['ä¸­å•å‡€æµå…¥-å‡€é¢'].std() / 10000

            # è®¡ç®—å°å•èµ„é‡‘æµç»Ÿè®¡
            small_inflow_mean = historical_flows['å°å•å‡€æµå…¥-å‡€é¢'].mean() / 10000
            small_inflow_std = historical_flows['å°å•å‡€æµå…¥-å‡€é¢'].std() / 10000

            # è®¡ç®—æ•£æˆ·èµ„é‡‘æµç»Ÿè®¡
            retail_inflow_mean = historical_flows['æ•£æˆ·å‡€æµå…¥-å‡€é¢'].mean() / 10000
            retail_inflow_std = historical_flows['æ•£æˆ·å‡€æµå…¥-å‡€é¢'].std() / 10000

            # è®¡ç®—èµ„é‡‘æµè¶‹åŠ¿
            if len(historical_flows) >= 5:
                recent_flows = historical_flows['ä¸»åŠ›å‡€æµå…¥-å‡€é¢'].values[-5:] / 10000
                flow_trend = np.polyfit(range(len(recent_flows)), recent_flows, 1)[0]
            else:
                flow_trend = 0

            # è®¡ç®—èµ„é‡‘æµè¿ç»­æ€§
            if len(historical_flows) >= 3:
                recent_signs = np.sign(historical_flows['ä¸»åŠ›å‡€æµå…¥-å‡€é¢'].values[-3:])
                flow_consistency = 1 if np.all(recent_signs > 0) else (-1 if np.all(recent_signs < 0) else 0)
            else:
                flow_consistency = 0

            return {
                'today_main': today_main_inflow,
                'today_retail': today_retail_inflow,
                'today_super': today_super_inflow,
                'today_big': today_big_inflow,
                'today_mid': today_mid_inflow,
                'today_small': today_small_inflow,
                'main_mean': main_inflow_mean,
                'main_std': main_inflow_std if np.isfinite(main_inflow_std) and main_inflow_std > 0 else 1.0,
                'super_mean': super_inflow_mean,
                'super_std': super_inflow_std if np.isfinite(super_inflow_std) and super_inflow_std > 0 else 1.0,
                'big_mean': big_inflow_mean,
                'big_std': big_inflow_std if np.isfinite(big_inflow_std) and big_inflow_std > 0 else 1.0,
                'mid_mean': mid_inflow_mean,
                'mid_std': mid_inflow_std if np.isfinite(mid_inflow_std) and mid_inflow_std > 0 else 1.0,
                'small_mean': small_inflow_mean,
                'small_std': small_inflow_std if np.isfinite(small_inflow_std) and small_inflow_std > 0 else 1.0,
                'retail_mean': retail_inflow_mean,
                'retail_std': retail_inflow_std if np.isfinite(retail_inflow_std) and retail_inflow_std > 0 else 1.0,
                'flow_trend': flow_trend,
                'flow_consistency': flow_consistency
            }
        except Exception as e:
            print(f"  âš ï¸ è·å–èµ„é‡‘æµå¼‚å¸¸ ({symbol}): {e}")
            return None

    def _incremental_cache_batch_processor(self, symbols, cache_path, processor_func, entity_name):
        """å¢é‡å¤„ç†æ•°æ®å¹¶ç¼“å­˜ç»“æœ"""
        task_start = time.time()
        today_str = datetime.now().strftime('%Y-%m-%d')
        cached_data = {}
        cache_filename = os.path.basename(cache_path)

        if os.path.exists(cache_path):
            try:
                with open(cache_path, 'r', encoding='utf-8') as f:
                    cache_file_content = json.load(f)
                    if cache_file_content.get('date') == today_str:
                        cached_data = cache_file_content.get('data', {})
                        print(f"âœ… ä»ç¼“å­˜æ–‡ä»¶ '{cache_filename}' åŠ è½½ {entity_name}ï¼Œå…± {len(cached_data)} æ¡è®°å½•")
            except (json.JSONDecodeError, IOError):
                print(f"âš ï¸ {cache_filename} ç¼“å­˜æ–‡ä»¶æŸåï¼Œå°†é‡æ–°è·å–")

        missing_symbols = [s for s in symbols if s not in cached_data]

        if not missing_symbols:
            print(f"âœ… æ‰€æœ‰ {entity_name} æ•°æ®å‡å·²åœ¨ç¼“å­˜ä¸­")
            self._log_performance(f"cache_process_{entity_name}", task_start)
            return cached_data

        print(f"ğŸ”„ éœ€ä¸º {len(missing_symbols)}/{len(symbols)} åªè‚¡ç¥¨è·å– {entity_name}...")

        newly_fetched_data = {}
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            f_to_s = {executor.submit(processor_func, s, f"T{i % self.max_workers + 1} "): (s, i) for i, s in
                      enumerate(missing_symbols)}
            for f in as_completed(f_to_s):
                s, i = f_to_s[f]
                try:
                    res = f.result(timeout=20)
                    if res:
                        newly_fetched_data[s] = res
                except TimeoutError:
                    print(f"  T{i % self.max_workers + 1} {s}: âŒ è·å– {entity_name} è¶…æ—¶")
                except Exception as e:
                    print(f"  T{i % self.max_workers + 1} {s}: âŒ è·å– {entity_name} å¼‚å¸¸: {str(e)[:50]}...")

        if newly_fetched_data:
            print(f"ğŸ”„ è·å–åˆ° {len(newly_fetched_data)} æ¡æ–°çš„ {entity_name} æ•°æ®")
            cached_data.update(newly_fetched_data)
            try:
                with open(cache_path, 'w', encoding='utf-8') as f:
                    json.dump({'date': today_str, 'data': cached_data}, f, ensure_ascii=False, indent=4)
                print(f"ğŸ’¾ {entity_name} ç¼“å­˜å·²æ›´æ–°è‡³ '{cache_filename}'ï¼Œæ€»è®¡ {len(cached_data)} æ¡è®°å½•")
            except IOError as e:
                print(f"âŒ ç¼“å­˜ {entity_name} å¤±è´¥: {e}")

        self._log_performance(f"cache_process_{entity_name}", task_start)
        return cached_data

    def get_hot_stocks(self):
        """è·å–çƒ­é—¨è‚¡ç¥¨åˆ—è¡¨"""
        task_start = time.time()
        today_str = datetime.now().strftime('%Y-%m-%d')
        cache_path = self.hot_stocks_cache_file
        cache_filename = os.path.basename(cache_path)

        if os.path.exists(cache_path):
            try:
                with open(cache_path, 'r', encoding='utf-8') as f:
                    cache_data = json.load(f)
                    if cache_data.get('date') == today_str:
                        stocks = cache_data.get('stocks', [])
                        if stocks:
                            print(f"âœ… ä»ç¼“å­˜æ–‡ä»¶ '{cache_filename}' åŠ è½½çƒ­é—¨è‚¡ç¥¨åˆ—è¡¨ï¼Œå…± {len(stocks)} æ¡è®°å½•")
                            self._log_performance("get_hot_stocks", task_start)
                            return stocks
                        else:
                            print(f"âš ï¸ ç¼“å­˜çš„çƒ­é—¨è‚¡åˆ—è¡¨ä¸ºç©ºï¼Œå°†é‡æ–°ä»APIè·å–")
            except (json.JSONDecodeError, IOError):
                print(f"âš ï¸ {cache_filename} ç¼“å­˜æ–‡ä»¶æŸåï¼Œå°†é‡æ–°è·å–")

        print("ğŸ”„ ä»APIè·å–çƒ­é—¨è‚¡ç¥¨æ’è¡Œæ¦œ...")
        hot_stock_codes = set()

        # è·å–ä¸œæ–¹è´¢å¯Œçƒ­é—¨è‚¡
        try:
            hot_rank_df = ak.stock_hot_rank_em()
            if hot_rank_df is not None and not hot_rank_df.empty:
                hot_stock_codes.update(hot_rank_df['ä»£ç '].tolist())
                print(f"âœ… ä»ä¸œæ–¹è´¢å¯Œè·å– {len(hot_stock_codes)} åªçƒ­é—¨è‚¡")
        except Exception as e:
            print(f"âš ï¸ è·å–ä¸œæ–¹è´¢å¯Œçƒ­é—¨è‚¡å¤±è´¥: {e}")

        # è·å–ç™¾åº¦çƒ­æœè‚¡ç¥¨
        try:
            baidu_date = datetime.now().strftime('%Y%m%d')
            baidu_hot_df = ak.stock_hot_search_baidu(symbol="Aè‚¡", date=baidu_date, time="ä»Šæ—¥")
            if baidu_hot_df is not None and not baidu_hot_df.empty:
                baidu_codes = baidu_hot_df['è‚¡ç¥¨ä»£ç '].tolist()
                initial_count = len(hot_stock_codes)
                hot_stock_codes.update(baidu_codes)
                print(f"âœ… ä»ç™¾åº¦çƒ­æœæ–°å¢ {len(hot_stock_codes) - initial_count} åªçƒ­é—¨è‚¡")
        except Exception as e:
            print(f"âš ï¸ è·å–ç™¾åº¦çƒ­æœè‚¡ç¥¨å¤±è´¥: {e}")

        # è·å–é›ªçƒçƒ­é—¨è‚¡ç¥¨
        try:
            xq_hot_df = ak.stock_hot_rank_detail_xq(symbol="æœ€çƒ­é—¨")
            if xq_hot_df is not None and not xq_hot_df.empty:
                xq_codes = xq_hot_df['è‚¡ç¥¨ä»£ç '].tolist()
                initial_count = len(hot_stock_codes)
                hot_stock_codes.update(xq_codes)
                print(f"âœ… ä»é›ªçƒçƒ­é—¨æ–°å¢ {len(hot_stock_codes) - initial_count} åªçƒ­é—¨è‚¡")
        except Exception as e:
            print(f"âš ï¸ è·å–é›ªçƒçƒ­é—¨è‚¡ç¥¨å¤±è´¥: {e}")

        # è·å–é¾™è™æ¦œè‚¡ç¥¨
        try:
            lhb_df = ak.stock_lhb_em()
            if lhb_df is not None and not lhb_df.empty:
                lhb_codes = lhb_df['ä»£ç '].tolist()
                initial_count = len(hot_stock_codes)
                hot_stock_codes.update(lhb_codes)
                print(f"âœ… ä»é¾™è™æ¦œæ–°å¢ {len(hot_stock_codes) - initial_count} åªçƒ­é—¨è‚¡")
        except Exception as e:
            print(f"âš ï¸ è·å–é¾™è™æ¦œè‚¡ç¥¨å¤±è´¥: {e}")

        if not hot_stock_codes:
            print("âŒ æœªä»ä»»ä½•æ¥æºè·å–åˆ°çƒ­é—¨è‚¡")
            self._log_performance("get_hot_stocks", task_start)
            return []

        print(f"â„¹ï¸ åˆå¹¶åå…± {len(hot_stock_codes)} åªçƒ­é—¨è‚¡ï¼Œå¼€å§‹è¿›è¡Œç­›é€‰...")

        try:
            # è·å–å®æ—¶è¡Œæƒ…è¿›è¡Œç­›é€‰
            spot_df = ak.stock_zh_a_spot_em()
            spot_df['ä»£ç '] = spot_df['ä»£ç '].apply(lambda x: f"SH{x}" if x.startswith('6') else f"SZ{x}")

            filtered_df = spot_df[spot_df['ä»£ç '].isin(hot_stock_codes)].copy()

            # ç­›é€‰æ¡ä»¶
            is_main = filtered_df['ä»£ç '].str.startswith(('SZ00', 'SH60'))  # ä¸»æ¿
            is_not_st = ~filtered_df['åç§°'].str.contains('ST')  # éST
            is_price_ok = (filtered_df['æœ€æ–°ä»·'] >= 5) & (filtered_df['æœ€æ–°ä»·'] <= 30)  # ä»·æ ¼åŒºé—´
            is_volume_ok = filtered_df['æˆäº¤é‡'] > 100000  # æˆäº¤é‡è¦è¶³å¤Ÿ
            is_turnover_ok = filtered_df['æ¢æ‰‹ç‡'] > 1.0  # æ¢æ‰‹ç‡è¦è¶³å¤Ÿ

            # åº”ç”¨ç­›é€‰æ¡ä»¶
            final_df = filtered_df[is_main & is_not_st & is_price_ok & is_volume_ok & is_turnover_ok]

            # é‡å‘½åå¹¶æå–ç»“æœ
            final_df = final_df.rename(columns={'åç§°': 'è‚¡ç¥¨åç§°'})
            final_stocks = final_df[['ä»£ç ', 'è‚¡ç¥¨åç§°']].to_dict('records')

            if final_stocks:
                with open(cache_path, 'w', encoding='utf-8') as f:
                    json.dump({'date': today_str, 'stocks': final_stocks}, f, ensure_ascii=False, indent=4)
                print(f"ğŸ’¾ çƒ­é—¨è‚¡ç¥¨åˆ—è¡¨å·²ç¼“å­˜è‡³ '{cache_filename}'ï¼Œç­›é€‰åå‰© {len(final_stocks)} æ¡")
            else:
                print("âš ï¸ æœªè·å–åˆ°ç¬¦åˆæ¡ä»¶çš„çƒ­é—¨è‚¡ï¼Œä¸æ›´æ–°ç¼“å­˜")

            self._log_performance("get_hot_stocks", task_start)
            return final_stocks
        except Exception as e:
            print(f"âŒ è·å–å®æ—¶è¡Œæƒ…è¿›è¡Œç­›é€‰å¤±è´¥: {e}")
            self._log_performance("get_hot_stocks", task_start)
            return []






    def get_tick_data(self, symbol, thread_id=""):
        """è·å–è‚¡ç¥¨çš„Tickæ•°æ®ï¼Œå§‹ç»ˆä»APIè·å–æœ€æ–°æ•°æ®"""
        task_start = time.time()

        tick_df, source = None, "æœªçŸ¥"
        try:
            # ä¼˜å…ˆä»è…¾è®¯è·å–
            tick_df = ak.stock_zh_a_tick_tx_js(symbol=symbol.lower())
            if tick_df is None or tick_df.empty: raise ValueError("Tencent data is empty")
            source = "è…¾è®¯"
            tick_df = tick_df.rename(
                columns={'æˆäº¤æ—¶é—´': 'æ—¶é—´', 'æˆäº¤ä»·æ ¼': 'æˆäº¤ä»·', 'æ€§è´¨': 'ä¹°å–ç›˜æ€§è´¨', 'ä»·æ ¼å˜åŠ¨': 'ä»·æ ¼å˜åŠ¨'})
        except Exception:
            try:
                # å°è¯•ä»ä¸œæ–¹è´¢å¯Œè·å–
                tick_df = ak.stock_intraday_em(symbol=symbol[2:])
                if tick_df is None or tick_df.empty: raise ValueError("East Money data is empty")
                source = "ä¸œæ–¹è´¢å¯Œ"
                tick_df = tick_df.rename(columns={'æ€§è´¨': 'ä¹°å–ç›˜æ€§è´¨'})
                tick_df['ä»·æ ¼å˜åŠ¨'] = tick_df['æˆäº¤ä»·'].diff().fillna(0)
            except Exception:
                # ä¸¤ä¸ªæ¥æºéƒ½å¤±è´¥
                self._log_performance("get_tick_data", task_start)
                return None, source

        # æ£€æŸ¥å¹¶å¤„ç†æ•°æ®
        if not all(c in tick_df.columns for c in ['æ—¶é—´', 'æˆäº¤ä»·', 'æˆäº¤é‡', 'ä¹°å–ç›˜æ€§è´¨', 'ä»·æ ¼å˜åŠ¨']):
            self._log_performance("get_tick_data", task_start)
            return None, source

        # æ•°æ®æ¸…æ´—å’Œé¢„å¤„ç†
        tick_df = tick_df[['æ—¶é—´', 'æˆäº¤ä»·', 'æˆäº¤é‡', 'ä¹°å–ç›˜æ€§è´¨', 'ä»·æ ¼å˜åŠ¨']].copy()
        tick_df['æ—¶é—´'] = pd.to_datetime(tick_df['æ—¶é—´'])
        tick_df = tick_df.sort_values('æ—¶é—´').reset_index(drop=True)
        tick_df = tick_df[tick_df['ä¹°å–ç›˜æ€§è´¨'].isin(['ä¹°ç›˜', 'å–ç›˜'])].copy()
        tick_df['æˆäº¤é‡'] = tick_df['æˆäº¤é‡'].astype(int)
        tick_df = tick_df[tick_df['æˆäº¤é‡'] > 0].copy()

        if tick_df.empty:
            self._log_performance("get_tick_data", task_start)
            return None, source

        # è®¡ç®—ä»·æ ¼å†²å‡»
        tick_df.loc[:, 'price_impact'] = tick_df['ä»·æ ¼å˜åŠ¨'] / tick_df['æˆäº¤é‡']
        tick_df['price_impact'].fillna(0, inplace=True)

        # è®¡ç®—æ—¶é—´é—´éš”
        tick_df['time_diff'] = tick_df['æ—¶é—´'].diff().dt.total_seconds()
        tick_df['time_diff'] = tick_df['time_diff'].fillna(0)

        # è®¡ç®—æˆäº¤é€Ÿç‡
        tick_df['volume_rate'] = tick_df['æˆäº¤é‡'] / (tick_df['time_diff'] + 0.001)

        # è®¡ç®—ç´¯è®¡æˆäº¤é‡
        tick_df['cum_volume'] = tick_df['æˆäº¤é‡'].cumsum()

        # è®¡ç®—ç´¯è®¡ä»·æ ¼å˜åŠ¨
        tick_df['cum_price_change'] = tick_df['ä»·æ ¼å˜åŠ¨'].cumsum()

        # è®¡ç®—VWAP
        tick_df['volume_price'] = tick_df['æˆäº¤ä»·'] * tick_df['æˆäº¤é‡']
        tick_df['cum_volume_price'] = tick_df['volume_price'].cumsum()
        tick_df['vwap'] = tick_df['cum_volume_price'] / tick_df['cum_volume']

        # è®¡ç®—ç§»åŠ¨å¹³å‡ä»·æ ¼
        tick_df['ma10'] = tick_df['æˆäº¤ä»·'].rolling(window=10).mean()

        # å¯ä»¥é€‰æ‹©æ€§åœ°ä¿å­˜å½“å‰æ•°æ®ä½œä¸ºå†å²å‚è€ƒï¼Œä½†ä¸ç”¨äºç¼“å­˜
        today_str = datetime.now().strftime('%Y-%m-%d')
        history_file = os.path.join(self.tick_cache_dir, f"{symbol}_{today_str}_history.csv")
        try:
            tick_df.to_csv(history_file, index=False)
        except Exception:
            pass  # å¿½ç•¥ä¿å­˜å†å²æ•°æ®çš„é”™è¯¯

        self._log_performance("get_tick_data", task_start)
        return tick_df, source

    def get_tick_data_batch(self, symbols):
        """æ‰¹é‡è·å–å¤šåªè‚¡ç¥¨çš„Tickæ•°æ®"""
        task_start = time.time()
        print(f"ğŸš€ å¼€å§‹å¤šçº¿ç¨‹è·å– {len(symbols)} åªè‚¡ç¥¨çš„tickæ•°æ®...")
        results = {}

        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            f_to_s = {executor.submit(self.get_tick_data, s, f"T{i % self.max_workers + 1} "): (s, i) for i, s in
                      enumerate(symbols)}
            for f in as_completed(f_to_s):
                s, i = f_to_s[f]
                log_prefix = f"  T{i % self.max_workers + 1} {s}:"
                try:
                    df, src = f.result(timeout=15)
                    if df is not None and not df.empty:
                        results[s] = df
                        print(f"{log_prefix} âœ… è·å–TickæˆåŠŸ (æ¥æº: {src})")
                    else:
                        print(f"{log_prefix} âŒ è·å–Tickå¤±è´¥")
                except TimeoutError:
                    print(f"{log_prefix} âŒ è·å–Tickè¶…æ—¶")
                except Exception as e:
                    print(f"{log_prefix} âŒ è·å–Tickå¼‚å¸¸: {e}")

        print(f"âœ… Tickæ•°æ®è·å–å®Œæˆï¼ŒæˆåŠŸ {len(results)}/{len(symbols)} åª")
        self._log_performance("get_tick_data_batch", task_start)
        return results

    def _filter_wash_trades(self, tick_df, symbol, name):
        """å¢å¼ºç‰ˆå¯¹å€’äº¤æ˜“è¯†åˆ«ç®—æ³•"""
        task_start = time.time()
        if tick_df is None or len(tick_df) < 20:
            self._log_performance("filter_wash_trades", task_start)
            return tick_df, 0

        df = tick_df.copy()
        total_volume = df['æˆäº¤é‡'].sum()
        if total_volume == 0:
            self._log_performance("filter_wash_trades", task_start)
            return df, 0

        # åŸºäºæ»šåŠ¨çª—å£è®¡ç®—æˆäº¤é‡ç»Ÿè®¡
        rolling_window = min(20, len(df) // 4)
        volume_mean = df['æˆäº¤é‡'].rolling(window=rolling_window, min_periods=5).mean().fillna(df['æˆäº¤é‡'].mean())
        volume_std = df['æˆäº¤é‡'].rolling(window=rolling_window, min_periods=5).std().fillna(df['æˆäº¤é‡'].std())
        volume_spike_threshold = volume_mean + 2 * volume_std

        # åˆå§‹åŒ–å¯¹å€’äº¤æ˜“æ ‡è®°
        is_wash_trade = pd.Series(False, index=df.index)

        # ç‰¹å¾1: æˆäº¤é‡å¼‚å¸¸ä½†ä»·æ ¼æ— å˜åŒ–
        is_spike = df['æˆäº¤é‡'] > volume_spike_threshold * 2
        is_no_price_change = df['ä»·æ ¼å˜åŠ¨'].abs() < 0.001
        feature1_mask = is_spike & is_no_price_change
        is_wash_trade[feature1_mask] = True

        # ç‰¹å¾2: è¿ç»­çš„ä¹°å–å¯¹å€’
        for i in range(1, len(df)):
            if is_wash_trade.iloc[i] or is_wash_trade.iloc[i - 1]:
                continue

            current_tick = df.iloc[i]
            previous_tick = df.iloc[i - 1]

            # æ—¶é—´é—´éš”è¿‡å¤§åˆ™è·³è¿‡
            if (current_tick['æ—¶é—´'] - previous_tick['æ—¶é—´']) > pd.Timedelta(seconds=5):
                continue

            # æ£€æŸ¥æˆäº¤é‡æ˜¯å¦éƒ½å¾ˆå¤§
            is_current_spike = current_tick['æˆäº¤é‡'] > volume_spike_threshold.iloc[i]
            is_previous_spike = previous_tick['æˆäº¤é‡'] > volume_spike_threshold.iloc[i - 1]
            if not (is_current_spike and is_previous_spike):
                continue

            # æ£€æŸ¥æˆäº¤é‡æ˜¯å¦æ¥è¿‘
            volume_diff_ratio = abs(current_tick['æˆäº¤é‡'] - previous_tick['æˆäº¤é‡']) / max(current_tick['æˆäº¤é‡'],
                                                                                            previous_tick['æˆäº¤é‡'])
            if volume_diff_ratio > 0.15:
                continue

            # æ£€æŸ¥ä¹°å–ç›˜æ€§è´¨æ˜¯å¦ç›¸å
            if current_tick['ä¹°å–ç›˜æ€§è´¨'] == previous_tick['ä¹°å–ç›˜æ€§è´¨']:
                continue

            # æ£€æŸ¥ä»·æ ¼å˜åŒ–æ˜¯å¦æ¥è¿‘äºé›¶
            net_price_change = current_tick['ä»·æ ¼å˜åŠ¨'] + previous_tick['ä»·æ ¼å˜åŠ¨']
            if abs(net_price_change) > 0.01:
                continue

            # æ ‡è®°ä¸ºå¯¹å€’äº¤æ˜“
            is_wash_trade.iloc[i] = True
            is_wash_trade.iloc[i - 1] = True

        # ç‰¹å¾3: é«˜é¢‘äº¤æ˜“æ¨¡å¼è¯†åˆ«
        if 'time_diff' in df.columns:
            # è¯†åˆ«é«˜é¢‘å°é¢äº¤æ˜“
            is_high_freq = df['time_diff'] < 0.5
            is_small_price_change = df['ä»·æ ¼å˜åŠ¨'].abs() < 0.001
            is_balanced_volume = (df['æˆäº¤é‡'] > volume_mean * 0.5) & (df['æˆäº¤é‡'] < volume_mean * 1.5)

            # è¿ç»­3ä¸ªä»¥ä¸Šæ»¡è¶³æ¡ä»¶çš„å¯èƒ½æ˜¯å¯¹å€’
            high_freq_count = (is_high_freq & is_small_price_change & is_balanced_volume).rolling(window=3).sum()
            is_wash_trade[high_freq_count >= 3] = True

        # ç‰¹å¾4: å¤§å•å¯¹å€’æ¨¡å¼
        # æ£€æµ‹çŸ­æ—¶é—´å†…å¤§å•ä¹°å–äº¤æ›¿ä¸”ä»·æ ¼å‡ ä¹ä¸å˜çš„æƒ…å†µ
        if len(df) > 10:
            for i in range(5, len(df)):
                window = df.iloc[i - 5:i + 1]
                buy_sells = window['ä¹°å–ç›˜æ€§è´¨'].tolist()

                # æ£€æŸ¥æ˜¯å¦æœ‰äº¤æ›¿çš„ä¹°å–æ¨¡å¼
                if 'ä¹°ç›˜' in buy_sells and 'å–ç›˜' in buy_sells and len(set(buy_sells)) > 1:
                    # æ£€æŸ¥ä»·æ ¼å˜åŠ¨
                    price_range = window['æˆäº¤ä»·'].max() - window['æˆäº¤ä»·'].min()
                    avg_volume = window['æˆäº¤é‡'].mean()

                    if price_range < 0.01 and avg_volume > volume_mean.iloc[i] * 1.5:
                        is_wash_trade.iloc[i - 5:i + 1] = True

        # è®¡ç®—å¯¹å€’äº¤æ˜“å æ¯”
        wash_trade_volume = df.loc[is_wash_trade, 'æˆäº¤é‡'].sum()
        clean_df = df.loc[~is_wash_trade]

        wash_trade_ratio = wash_trade_volume / total_volume
        if wash_trade_ratio > 0.01:
            print(f"    - {symbol} ({name}): è¯†åˆ«åˆ°å¯¹å€’å«Œç–‘ï¼Œæˆäº¤é‡å æ¯”: {wash_trade_ratio:.2%}")
        else:
            print(f"    - {symbol} ({name}): æœªè¯†åˆ«åˆ°æ˜æ˜¾å¯¹å€’å«Œç–‘")

        self._log_performance("filter_wash_trades", task_start)
        return clean_df, wash_trade_ratio

    def analyze_trade_direction(self, tick_df):
        """åˆ†æäº¤æ˜“æ–¹å‘å’Œä¹°å–åŠ›é‡å¯¹æ¯”"""
        task_start = time.time()
        if tick_df is None or tick_df.empty:
            self._log_performance("analyze_trade_direction", task_start)
            return {}

        # åŸºæœ¬ä¹°å–ç›˜åˆ†æ
        buy_volume = tick_df.loc[tick_df['ä¹°å–ç›˜æ€§è´¨'] == 'ä¹°ç›˜', 'æˆäº¤é‡'].sum()
        sell_volume = tick_df.loc[tick_df['ä¹°å–ç›˜æ€§è´¨'] == 'å–ç›˜', 'æˆäº¤é‡'].sum()
        total_volume = buy_volume + sell_volume

        # è®¡ç®—ä¹°å–æ¯”ç‡
        active_buy_ratio = buy_volume / total_volume if total_volume > 0 else 0.5

        # è®¡ç®—å‡€ä¹°å…¥é‡
        net_buy_volume = buy_volume - sell_volume

        # è®¡ç®—ä¹°å–ç›˜ä»·æ ¼å†²å‡»
        buy_impact = tick_df.loc[tick_df['ä¹°å–ç›˜æ€§è´¨'] == 'ä¹°ç›˜', 'price_impact'].mean()
        sell_impact = tick_df.loc[tick_df['ä¹°å–ç›˜æ€§è´¨'] == 'å–ç›˜', 'price_impact'].mean()

        # è®¡ç®—ä¹°å–ç›˜å¹³å‡æˆäº¤é‡
        avg_buy_size = tick_df.loc[tick_df['ä¹°å–ç›˜æ€§è´¨'] == 'ä¹°ç›˜', 'æˆäº¤é‡'].mean()
        avg_sell_size = tick_df.loc[tick_df['ä¹°å–ç›˜æ€§è´¨'] == 'å–ç›˜', 'æˆäº¤é‡'].mean()

        # è®¡ç®—å¤§å•æ¯”ä¾‹
        large_threshold = tick_df['æˆäº¤é‡'].quantile(0.8)
        large_buy = tick_df[(tick_df['ä¹°å–ç›˜æ€§è´¨'] == 'ä¹°ç›˜') & (tick_df['æˆäº¤é‡'] > large_threshold)]['æˆäº¤é‡'].sum()
        large_sell = tick_df[(tick_df['ä¹°å–ç›˜æ€§è´¨'] == 'å–ç›˜') & (tick_df['æˆäº¤é‡'] > large_threshold)]['æˆäº¤é‡'].sum()
        large_buy_ratio = large_buy / buy_volume if buy_volume > 0 else 0
        large_sell_ratio = large_sell / sell_volume if sell_volume > 0 else 0

        # åˆ†æ—¶æ®µåˆ†æ
        morning_df = tick_df[tick_df['æ—¶é—´'].dt.time < pd.to_datetime('11:30:00').time()]
        afternoon_df = tick_df[tick_df['æ—¶é—´'].dt.time >= pd.to_datetime('13:00:00').time()]

        morning_buy = morning_df.loc[morning_df['ä¹°å–ç›˜æ€§è´¨'] == 'ä¹°ç›˜', 'æˆäº¤é‡'].sum()
        morning_sell = morning_df.loc[morning_df['ä¹°å–ç›˜æ€§è´¨'] == 'å–ç›˜', 'æˆäº¤é‡'].sum()
        afternoon_buy = afternoon_df.loc[afternoon_df['ä¹°å–ç›˜æ€§è´¨'] == 'ä¹°ç›˜', 'æˆäº¤é‡'].sum()
        afternoon_sell = afternoon_df.loc[afternoon_df['ä¹°å–ç›˜æ€§è´¨'] == 'å–ç›˜', 'æˆäº¤é‡'].sum()

        morning_net = morning_buy - morning_sell
        afternoon_net = afternoon_buy - afternoon_sell

        # è®¡ç®—åŠ¨é‡æ¯”ç‡
        momentum_ratio = afternoon_net / net_buy_volume if net_buy_volume != 0 else 0

        # è®¡ç®—æ”¶ç›˜å‰15åˆ†é’Ÿçš„ä¹°å–æƒ…å†µ
        closing_time = pd.to_datetime('14:45:00').time()
        closing_df = tick_df[tick_df['æ—¶é—´'].dt.time >= closing_time]
        closing_buy = closing_df.loc[closing_df['ä¹°å–ç›˜æ€§è´¨'] == 'ä¹°ç›˜', 'æˆäº¤é‡'].sum()
        closing_sell = closing_df.loc[closing_df['ä¹°å–ç›˜æ€§è´¨'] == 'å–ç›˜', 'æˆäº¤é‡'].sum()
        closing_net = closing_buy - closing_sell
        closing_ratio = closing_net / net_buy_volume if net_buy_volume != 0 else 0

        # è®¡ç®—ä¹°å–ç›˜è¿ç»­æ€§
        buy_runs = self._calculate_runs(tick_df, 'ä¹°ç›˜')
        sell_runs = self._calculate_runs(tick_df, 'å–ç›˜')

        # è®¡ç®—ä¹°å–ç›˜é›†ä¸­åº¦
        buy_concentration = self._calculate_concentration(tick_df, 'ä¹°ç›˜')
        sell_concentration = self._calculate_concentration(tick_df, 'å–ç›˜')

        # è®¡ç®—ä¹°å–ç›˜å¼ºåº¦å˜åŒ–
        buy_strength_change = self._calculate_strength_change(tick_df, 'ä¹°ç›˜')
        sell_strength_change = self._calculate_strength_change(tick_df, 'å–ç›˜')

        result = {
            'net_buy_volume': net_buy_volume,
            'active_buy_ratio': active_buy_ratio,
            'buy_impact': buy_impact,
            'sell_impact': sell_impact,
            'avg_buy_size': avg_buy_size,
            'avg_sell_size': avg_sell_size,
            'large_buy_ratio': large_buy_ratio,
            'large_sell_ratio': large_sell_ratio,
            'morning_net': morning_net,
            'afternoon_net': afternoon_net,
            'momentum_ratio': momentum_ratio,
            'closing_net': closing_net,
            'closing_ratio': closing_ratio,
            'buy_runs': buy_runs,
            'sell_runs': sell_runs,
            'buy_concentration': buy_concentration,
            'sell_concentration': sell_concentration,
            'buy_strength_change': buy_strength_change,
            'sell_strength_change': sell_strength_change
        }

        self._log_performance("analyze_trade_direction", task_start)
        return result

    def _calculate_runs(self, tick_df, side):
        """è®¡ç®—ä¹°å–ç›˜è¿ç»­æ€§"""
        if tick_df.empty:
            return 0

        side_df = tick_df[tick_df['ä¹°å–ç›˜æ€§è´¨'] == side]
        if side_df.empty:
            return 0

        # è®¡ç®—è¿ç»­äº¤æ˜“çš„æœ€å¤§é•¿åº¦
        side_df = side_df.sort_values('æ—¶é—´')
        side_df['time_diff'] = side_df['æ—¶é—´'].diff().dt.total_seconds()

        # å®šä¹‰è¿ç»­äº¤æ˜“çš„æ—¶é—´é˜ˆå€¼ï¼ˆä¾‹å¦‚5ç§’å†…ï¼‰
        continuous_mask = side_df['time_diff'] < 5

        # æ ‡è®°æ¯ä¸ªè¿ç»­åºåˆ—çš„å¼€å§‹
        run_starts = ~continuous_mask
        run_ids = run_starts.cumsum()

        # è®¡ç®—æ¯ä¸ªè¿ç»­åºåˆ—çš„é•¿åº¦
        run_lengths = side_df.groupby(run_ids).size()

        # è¿”å›æœ€é•¿è¿ç»­åºåˆ—çš„é•¿åº¦
        return run_lengths.max() if not run_lengths.empty else 1

    def _calculate_concentration(self, tick_df, side):
        """è®¡ç®—ä¹°å–ç›˜é›†ä¸­åº¦"""
        if tick_df.empty:
            return 0

        side_df = tick_df[tick_df['ä¹°å–ç›˜æ€§è´¨'] == side]
        if side_df.empty or len(side_df) < 5:
            return 0

        # å°†äº¤æ˜“æ—¶é—´åˆ†æˆå¤šä¸ªæ—¶é—´æ®µ
        side_df['hour'] = side_df['æ—¶é—´'].dt.hour
        side_df['minute_group'] = (side_df['æ—¶é—´'].dt.minute // 15)
        side_df['time_group'] = side_df['hour'].astype(str) + '_' + side_df['minute_group'].astype(str)

        # è®¡ç®—æ¯ä¸ªæ—¶é—´æ®µçš„æˆäº¤é‡
        volume_by_time = side_df.groupby('time_group')['æˆäº¤é‡'].sum()

        # è®¡ç®—é›†ä¸­åº¦ï¼ˆä½¿ç”¨åŸºå°¼ç³»æ•°æˆ–èµ«èŠ¬è¾¾å°”æŒ‡æ•°ï¼‰
        total_volume = volume_by_time.sum()
        if total_volume == 0:
            return 0

        # è®¡ç®—èµ«èŠ¬è¾¾å°”æŒ‡æ•°
        market_shares = (volume_by_time / total_volume)
        herfindahl_index = (market_shares ** 2).sum()

        return herfindahl_index

    def _calculate_strength_change(self, tick_df, side):
        """è®¡ç®—ä¹°å–ç›˜å¼ºåº¦å˜åŒ–"""
        if tick_df.empty:
            return 0

        side_df = tick_df[tick_df['ä¹°å–ç›˜æ€§è´¨'] == side]
        if side_df.empty or len(side_df) < 10:
            return 0

        # å°†æ•°æ®åˆ†ä¸ºå‰åŠéƒ¨åˆ†å’ŒååŠéƒ¨åˆ†
        midpoint = len(side_df) // 2
        first_half = side_df.iloc[:midpoint]
        second_half = side_df.iloc[midpoint:]

        # è®¡ç®—å‰ååŠéƒ¨åˆ†çš„å¹³å‡æˆäº¤é‡
        first_half_avg = first_half['æˆäº¤é‡'].mean()
        second_half_avg = second_half['æˆäº¤é‡'].mean()

        # è®¡ç®—å¼ºåº¦å˜åŒ–ç‡
        if first_half_avg == 0:
            return 0

        strength_change = (second_half_avg - first_half_avg) / first_half_avg
        return strength_change

    def analyze_microstructure(self, tick_df):
        """åˆ†æå¸‚åœºå¾®è§‚ç»“æ„æŒ‡æ ‡"""
        task_start = time.time()
        if tick_df is None or tick_df.empty:
            self._log_performance("analyze_microstructure", task_start)
            return {}

        # è®¡ç®—ä»·æ ¼å†²å‡»æŒ‡æ ‡
        avg_abs_impact = tick_df['price_impact'].abs().mean()
        buy_impact = tick_df.loc[tick_df['ä¹°å–ç›˜æ€§è´¨'] == 'ä¹°ç›˜', 'price_impact'].mean()
        sell_impact = tick_df.loc[tick_df['ä¹°å–ç›˜æ€§è´¨'] == 'å–ç›˜', 'price_impact'].mean()
        impact_asymmetry = buy_impact - sell_impact

        # è®¡ç®—Kyle's Lambda (ä»·æ ¼å†²å‡»ç³»æ•°)
        # ä½¿ç”¨å›å½’æ–¹æ³•ä¼°è®¡ä»·æ ¼å˜åŠ¨ä¸æˆäº¤é‡çš„å…³ç³»
        try:
            X = tick_df['æˆäº¤é‡'].values.reshape(-1, 1)
            y = tick_df['ä»·æ ¼å˜åŠ¨'].values
            model = LinearRegression()
            model.fit(X, y)
            kyle_lambda = model.coef_[0]
        except:
            kyle_lambda = avg_abs_impact

        # è®¡ç®—æœ‰æ•ˆä»·å·® (Effective Spread)
        # ä½¿ç”¨ä»·æ ¼å†²å‡»çš„ä¸¤å€ä½œä¸ºæœ‰æ•ˆä»·å·®çš„ä¼°è®¡
        effective_spread = 2 * avg_abs_impact

        # è®¡ç®—æˆäº¤é‡åŠ æƒä»·æ ¼æ³¢åŠ¨ç‡
        vwap_price = np.sum(tick_df['æˆäº¤ä»·'] * tick_df['æˆäº¤é‡']) / np.sum(tick_df['æˆäº¤é‡'])
        vwap_volatility = np.sqrt(
            np.sum(((tick_df['æˆäº¤ä»·'] - vwap_price) ** 2) * tick_df['æˆäº¤é‡']) / np.sum(tick_df['æˆäº¤é‡']))

        # è®¡ç®—äº¤æ˜“æ´»è·ƒåº¦
        if 'time_diff' in tick_df.columns:
            avg_time_between_trades = tick_df['time_diff'].mean()
            trade_intensity = 1 / (avg_time_between_trades + 0.001)
        else:
            avg_time_between_trades = 0
            trade_intensity = 0

        # è®¡ç®—å¤§å•å†²å‡»
        large_threshold = tick_df['æˆäº¤é‡'].quantile(0.8)
        large_trades = tick_df[tick_df['æˆäº¤é‡'] > large_threshold]
        large_impact = large_trades['price_impact'].abs().mean() if not large_trades.empty else 0

        # è®¡ç®—ä»·æ ¼è¶‹åŠ¿
        if len(tick_df) > 1:
            first_price = tick_df['æˆäº¤ä»·'].iloc[0]
            last_price = tick_df['æˆäº¤ä»·'].iloc[-1]
            price_trend = (last_price - first_price) / first_price
        else:
            price_trend = 0

        # è®¡ç®—æˆäº¤é‡è¶‹åŠ¿
        if len(tick_df) > 20:
            volume_trend = tick_df['æˆäº¤é‡'].rolling(window=10).mean().pct_change().mean()
        else:
            volume_trend = 0

        # è®¡ç®—ä¹°å–å‹åŠ›æ¯”
        buy_pressure = tick_df[tick_df['ä¹°å–ç›˜æ€§è´¨'] == 'ä¹°ç›˜']['price_impact'].abs().mean() if not tick_df[
            tick_df['ä¹°å–ç›˜æ€§è´¨'] == 'ä¹°ç›˜'].empty else 0
        sell_pressure = tick_df[tick_df['ä¹°å–ç›˜æ€§è´¨'] == 'å–ç›˜']['price_impact'].abs().mean() if not tick_df[
            tick_df['ä¹°å–ç›˜æ€§è´¨'] == 'å–ç›˜'].empty else 0
        pressure_ratio = buy_pressure / sell_pressure if sell_pressure > 0 else 1.0

        # è®¡ç®—ä»·æ ¼å¼¹æ€§
        if len(tick_df) > 20:
            # ä½¿ç”¨æ»šåŠ¨çª—å£è®¡ç®—ä»·æ ¼å˜åŠ¨ä¸æˆäº¤é‡çš„æ¯”ç‡
            tick_df['price_volume_ratio'] = tick_df['ä»·æ ¼å˜åŠ¨'].abs() / tick_df['æˆäº¤é‡']
            price_elasticity = tick_df['price_volume_ratio'].mean()
        else:
            price_elasticity = 0

        # è®¡ç®—ä»·æ ¼åè½¬
        if len(tick_df) > 20:
            # è®¡ç®—ä»·æ ¼å˜åŠ¨çš„è‡ªç›¸å…³æ€§
            price_changes = tick_df['ä»·æ ¼å˜åŠ¨']
            price_autocorr = price_changes.autocorr(lag=1)
            price_reversal = -price_autocorr  # è´Ÿçš„è‡ªç›¸å…³è¡¨ç¤ºåè½¬
        else:
            price_reversal = 0

        # è®¡ç®—æµåŠ¨æ€§æŒ‡æ ‡
        if 'vwap' in tick_df.columns:
            # è®¡ç®—ä»·æ ¼åç¦»VWAPçš„ç¨‹åº¦
            tick_df['price_vwap_diff'] = (tick_df['æˆäº¤ä»·'] - tick_df['vwap']) / tick_df['vwap']
            liquidity_index = tick_df['price_vwap_diff'].abs().mean()
        else:
            liquidity_index = 0

        # è®¡ç®—AmihudéæµåŠ¨æ€§æŒ‡æ ‡
        if len(tick_df) > 10:
            # å°†æ•°æ®åˆ†æˆå¤šä¸ªæ—¶é—´æ®µ
            tick_df['minute'] = tick_df['æ—¶é—´'].dt.minute
            grouped = tick_df.groupby('minute')

            # è®¡ç®—æ¯ä¸ªæ—¶é—´æ®µçš„ä»·æ ¼å˜åŠ¨ç»å¯¹å€¼ä¸æˆäº¤é‡çš„æ¯”ç‡
            amihud_values = []
            for _, group in grouped:
                if len(group) > 1:
                    price_change = abs(group['æˆäº¤ä»·'].iloc[-1] - group['æˆäº¤ä»·'].iloc[0])
                    volume = group['æˆäº¤é‡'].sum()
                    if volume > 0:
                        amihud_values.append(price_change / volume)

            amihud_illiquidity = np.mean(amihud_values) if amihud_values else 0
        else:
            amihud_illiquidity = 0

        result = {
            'avg_abs_impact': avg_abs_impact,
            'impact_asymmetry': impact_asymmetry,
            'kyle_lambda': kyle_lambda,
            'effective_spread': effective_spread,
            'vwap_volatility': vwap_volatility,
            'trade_intensity': trade_intensity,
            'large_impact': large_impact,
            'price_trend': price_trend,
            'volume_trend': volume_trend,
            'pressure_ratio': pressure_ratio,
            'price_elasticity': price_elasticity,
            'price_reversal': price_reversal,
            'liquidity_index': liquidity_index,
            'amihud_illiquidity': amihud_illiquidity
        }

        self._log_performance("analyze_microstructure", task_start)
        return result

    def _calculate_score_v8(self, metrics):
        """è®¡ç®—ç»¼åˆè¯„åˆ† - V8ç‰ˆæœ¬"""
        task_start = time.time()

        # æå–æŒ‡æ ‡
        fund_flow_z_score = metrics.get('fund_flow_z_score', 0)
        super_flow_z_score = metrics.get('super_flow_z_score', 0)
        flow_consistency = metrics.get('flow_consistency', 0)
        net_buy_adv_ratio = metrics.get('net_buy_adv_ratio', 0)
        impact_atr_ratio = metrics.get('impact_atr_ratio', 0)
        excess_return = metrics.get('excess_return', 0)
        momentum_ratio = metrics.get('momentum_ratio', 0)
        closing_ratio = metrics.get('closing_ratio', 0)
        wash_trade_ratio = metrics.get('wash_trade_ratio', 0)
        pressure_ratio = metrics.get('pressure_ratio', 1.0)
        large_buy_ratio = metrics.get('large_buy_ratio', 0)
        large_sell_ratio = metrics.get('large_sell_ratio', 0)
        impact_asymmetry = metrics.get('impact_asymmetry', 0)
        volume_trend = metrics.get('volume_trend', 0)
        price_reversal = metrics.get('price_reversal', 0)
        buy_concentration = metrics.get('buy_concentration', 0)
        rsi = metrics.get('rsi', 50)

        # èµ„é‡‘æµè¯„åˆ† (0-40åˆ†)
        fund_flow_score = np.clip(fund_flow_z_score * 20, -30, 30)
        super_flow_score = np.clip(super_flow_z_score * 10, -10, 10)
        flow_consistency_score = flow_consistency * 5  # -5åˆ°5åˆ†

        # å‡€ä¹°å…¥è¯„åˆ† (0-20åˆ†)
        net_buy_score = np.clip(net_buy_adv_ratio / 0.1 * 20, -20, 20)

        # ä»·æ ¼å†²å‡»è¯„åˆ† (0-15åˆ†)
        impact_score = 15 - (impact_atr_ratio / 0.1) * 30
        impact_score = np.clip(impact_score, -15, 15)

        # ä¹°å–å‹åŠ›æ¯”è¯„åˆ† (0-10åˆ†)
        pressure_score = 0
        if pressure_ratio > 1.2:
            pressure_score = min((pressure_ratio - 1.2) * 10, 10)
        elif pressure_ratio < 0.8:
            pressure_score = max((pressure_ratio - 0.8) * 10, -10)

        # å¤§å•æ¯”ä¾‹è¯„åˆ† (0-10åˆ†)
        large_trade_score = (large_buy_ratio - large_sell_ratio) * 20
        large_trade_score = np.clip(large_trade_score, -10, 10)

        # åŠ¨é‡è¯„åˆ† (0-15åˆ†)
        momentum_score = 0
        if momentum_ratio > 0.6:
            momentum_score = 10 * min((momentum_ratio - 0.6) / 0.4, 1.0)
        elif momentum_ratio < 0:
            momentum_score = -10

        # æ”¶ç›˜åŠ¨é‡è¯„åˆ† (0-5åˆ†)
        closing_score = 0
        if closing_ratio > 0.2:
            closing_score = 5 * min((closing_ratio - 0.2) / 0.3, 1.0)
        elif closing_ratio < -0.2:
            closing_score = -5 * min((abs(closing_ratio) - 0.2) / 0.3, 1.0)

        # è¶…é¢æ”¶ç›Šè¯„åˆ† (0-5åˆ†)
        alpha_score = np.clip(excess_return / 2 * 5, -5, 5)

        # å†²å‡»ä¸å¯¹ç§°æ€§è¯„åˆ† (0-5åˆ†)
        asymmetry_score = np.clip(impact_asymmetry * 100, -5, 5)

        # æˆäº¤é‡è¶‹åŠ¿è¯„åˆ† (0-5åˆ†)
        vol_trend_score = np.clip(volume_trend * 50, -5, 5)

        # ä»·æ ¼åè½¬è¯„åˆ† (0-5åˆ†)
        reversal_score = np.clip(price_reversal * 10, -5, 5)

        # ä¹°ç›˜é›†ä¸­åº¦è¯„åˆ† (0-5åˆ†)
        concentration_score = np.clip((buy_concentration - 0.2) * 20, -5, 5)

        # RSIè¯„åˆ† (0-5åˆ†)
        rsi_score = 0
        if rsi > 70:
            rsi_score = -5 * min((rsi - 70) / 15, 1.0)  # è¿‡çƒ­æƒ©ç½š
        elif rsi < 30:
            rsi_score = 5 * min((30 - rsi) / 15, 1.0)  # è¶…è·Œå¥–åŠ±

        # å¯¹å€’äº¤æ˜“æƒ©ç½š (0-15åˆ†)
        wash_trade_penalty = np.clip(wash_trade_ratio * 50, 0, 15)

        # è®¡ç®—æ€»åˆ†
        total_score = (
                fund_flow_score + super_flow_score + flow_consistency_score +
                net_buy_score + impact_score +
                pressure_score + large_trade_score +
                momentum_score + closing_score +
                alpha_score + asymmetry_score +
                vol_trend_score + reversal_score +
                concentration_score + rsi_score -
                wash_trade_penalty
        )

        self._log_performance("calculate_score", task_start)
        return np.clip(total_score, -100, 100)


    def analyze_stock_worker(self, stock, tick_df, market_performance, hist_metrics, fund_flow_data, volume_ratio,
                             current_price, change_pct, turnover_rate):
        """åˆ†æå•åªè‚¡ç¥¨çš„å·¥ä½œå‡½æ•°"""
        task_start = time.time()
        symbol = stock['ä»£ç ']
        name = stock['è‚¡ç¥¨åç§°']

        # è¿‡æ»¤å¯¹å€’äº¤æ˜“
        clean_tick_df, wash_trade_ratio = self._filter_wash_trades(tick_df, symbol, name)

        if clean_tick_df is None or clean_tick_df.empty:
            self._log_performance("analyze_stock_worker", task_start)
            return None

        # è®¡ç®—æ—¥å†…ä»·æ ¼å˜åŒ–
        first_price = float(clean_tick_df['æˆäº¤ä»·'].iloc[0])
        last_price = float(clean_tick_df['æˆäº¤ä»·'].iloc[-1])
        intraday_change = ((last_price - first_price) / first_price) * 100 if first_price > 0 else 0
        excess_return = intraday_change - market_performance

        # åˆ†æäº¤æ˜“æ–¹å‘
        trade_direction = self.analyze_trade_direction(clean_tick_df)
        net_buy_volume = trade_direction.get('net_buy_volume', 0)

        # åˆ†æå¸‚åœºå¾®è§‚ç»“æ„
        microstructure = self.analyze_microstructure(clean_tick_df)

        # è·å–å†å²æŒ‡æ ‡
        adv20 = hist_metrics.get('adv20', 0)
        atr20 = hist_metrics.get('atr20', 0)
        volatility = hist_metrics.get('volatility', 0)
        trend_strength = hist_metrics.get('trend_strength', 0)
        rsi = hist_metrics.get('rsi', 50)
        macd = hist_metrics.get('macd', 0)
        macd_signal = hist_metrics.get('macd_signal', 0)
        bb_width = hist_metrics.get('bb_width', 0)
        beta = hist_metrics.get('beta', 1.0)
        alpha = hist_metrics.get('alpha', 0)
        momentum_5d = hist_metrics.get('momentum_5d', 0)
        momentum_10d = hist_metrics.get('momentum_10d', 0)
        price_volume_corr = hist_metrics.get('price_volume_corr', 0)

        # è®¡ç®—å…³é”®æ¯”ç‡
        net_buy_adv_ratio = (net_buy_volume / adv20) if adv20 > 0 else 0
        impact_atr_ratio = (microstructure.get('avg_abs_impact', 0) / atr20) if atr20 > 0 else 0

        # å‡†å¤‡è¯„åˆ†æŒ‡æ ‡
        metrics = {
            'net_buy_adv_ratio': net_buy_adv_ratio,
            'impact_atr_ratio': impact_atr_ratio,
            'excess_return': excess_return,
            'momentum_ratio': trade_direction.get('momentum_ratio', 0),
            'closing_ratio': trade_direction.get('closing_ratio', 0),
            'wash_trade_ratio': wash_trade_ratio,
            'active_buy_ratio': trade_direction.get('active_buy_ratio', 0.5),
            'large_buy_ratio': trade_direction.get('large_buy_ratio', 0),
            'large_sell_ratio': trade_direction.get('large_sell_ratio', 0),
            'pressure_ratio': microstructure.get('pressure_ratio', 1.0),
            'impact_asymmetry': microstructure.get('impact_asymmetry', 0),
            'volume_trend': microstructure.get('volume_trend', 0),
            'price_reversal': microstructure.get('price_reversal', 0),
            'buy_concentration': trade_direction.get('buy_concentration', 0),
            'volatility': volatility,
            'trend_strength': trend_strength,
            'rsi': rsi,
            'macd': macd,
            'macd_signal': macd_signal,
            'bb_width': bb_width,
            'beta': beta,
            'alpha': alpha,
            'momentum_5d': momentum_5d,
            'momentum_10d': momentum_10d,
            'price_volume_corr': price_volume_corr,
            'turnover_rate': turnover_rate
        }

        # æ·»åŠ èµ„é‡‘æµæŒ‡æ ‡
        if fund_flow_data:
            # ä¸»åŠ›èµ„é‡‘æµZ-score
            main_mean = fund_flow_data.get('main_mean', 0)
            main_std = fund_flow_data.get('main_std', 1)
            today_main = fund_flow_data.get('today_main', 0)
            fund_flow_z_score = (today_main - main_mean) / main_std

            # è¶…å¤§å•èµ„é‡‘æµZ-score
            super_mean = fund_flow_data.get('super_mean', 0)
            super_std = fund_flow_data.get('super_std', 1)
            today_super = fund_flow_data.get('today_super', 0)
            super_flow_z_score = (today_super - super_mean) / super_std

            # èµ„é‡‘æµä¸€è‡´æ€§
            flow_consistency = fund_flow_data.get('flow_consistency', 0)

            metrics['fund_flow_z_score'] = fund_flow_z_score
            metrics['super_flow_z_score'] = super_flow_z_score
            metrics['flow_consistency'] = flow_consistency

        # è®¡ç®—V8è¯„åˆ†
        score = self._calculate_score_v8(metrics)

        # æ„å»ºç»“æœ
        result = {
            'name': name,
            'score': score,
            'model_version': "V8",
            'current_price': current_price,
            'change_pct': change_pct,
            'turnover_rate': turnover_rate,
            'fund_flow_z_score': metrics.get('fund_flow_z_score', 0),
            'super_flow_z_score': metrics.get('super_flow_z_score', 0),
            'flow_consistency': metrics.get('flow_consistency', 0),
            'net_buy_adv_ratio': net_buy_adv_ratio,
            'impact_atr_ratio': impact_atr_ratio,
            'intraday_change': intraday_change,
            'excess_return': excess_return,
            'active_buy_ratio': trade_direction.get('active_buy_ratio', 0.5),
            'momentum_ratio': trade_direction.get('momentum_ratio', 0),
            'closing_ratio': trade_direction.get('closing_ratio', 0),
            'volume_ratio': volume_ratio,
            'wash_trade_ratio': wash_trade_ratio,
            'pressure_ratio': microstructure.get('pressure_ratio', 1.0),
            'large_buy_ratio': trade_direction.get('large_buy_ratio', 0),
            'large_sell_ratio': trade_direction.get('large_sell_ratio', 0),
            'kyle_lambda': microstructure.get('kyle_lambda', 0),
            'effective_spread': microstructure.get('effective_spread', 0),
            'volatility': volatility,
            'rsi': rsi,
            'trend_strength': trend_strength,
            'macd': macd,
            'macd_signal': macd_signal,
            'price_reversal': microstructure.get('price_reversal', 0),
            'buy_concentration': trade_direction.get('buy_concentration', 0),
            'beta': beta,
            'alpha': alpha
        }

        self._log_performance("analyze_stock_worker", task_start)
        return (symbol, result)



    def _get_realtime_quotes_worker(self):
        """è·å–å®æ—¶è¡Œæƒ…æ•°æ®"""
        task_start = time.time()
        try:
            spot_df = ak.stock_zh_a_spot_em()
            spot_df['ä»£ç '] = spot_df['ä»£ç '].apply(lambda x: f"SH{x}" if x.startswith('6') else f"SZ{x}")
            volume_ratios = spot_df.set_index('ä»£ç ')['é‡æ¯”'].to_dict()
            current_prices = spot_df.set_index('ä»£ç ')['æœ€æ–°ä»·'].to_dict()
            change_pcts = spot_df.set_index('ä»£ç ')['æ¶¨è·Œå¹…'].to_dict()
            turnover_rates = spot_df.set_index('ä»£ç ')['æ¢æ‰‹ç‡'].to_dict()
            self._log_performance("get_realtime_quotes", task_start)
            return volume_ratios, current_prices, change_pcts, turnover_rates
        except Exception as e:
            print(f"\nâŒ è·å–å®æ—¶è¡Œæƒ…å¤±è´¥: {e}")
            self._log_performance("get_realtime_quotes", task_start)
            return {}, {}, {}, {}

    def analyze_stocks(self):
        """åˆ†ææ‰€æœ‰çƒ­é—¨è‚¡ç¥¨"""
        total_start = time.time()
        market_performance = self._get_market_performance()
        all_stocks = self.get_hot_stocks()
        if not all_stocks: return []

        symbols = [stock['ä»£ç '] for stock in all_stocks]

        print("\nğŸ“Š æ­¥éª¤ 1/3: æ‰¹é‡è·å–å†å²å’Œèµ„é‡‘æµæ•°æ®...")
        historical_metrics = self._incremental_cache_batch_processor(symbols, self.historical_metrics_cache_file,
                                                                     self._get_historical_data, "å†å²è¡Œæƒ…")
        fund_flow_data = self._incremental_cache_batch_processor(symbols, self.fund_flow_cache_file,
                                                                 self._get_fund_flow_with_history, "èµ„é‡‘æµ")

        print("\nğŸ“Š æ­¥éª¤ 2/3: å¹¶è¡Œè·å–Tickæ•°æ®å’Œå®æ—¶è¡Œæƒ…...")
        with ThreadPoolExecutor(max_workers=2) as executor:
            tick_future = executor.submit(self.get_tick_data_batch, symbols)
            realtime_future = executor.submit(self._get_realtime_quotes_worker)

            tick_data_results = tick_future.result()
            volume_ratios, current_prices, change_pcts, turnover_rates = realtime_future.result()

        if volume_ratios:
            print(f"âœ… æˆåŠŸè·å– {len(volume_ratios)} åªè‚¡ç¥¨çš„å®æ—¶è¡Œæƒ…")
        else:
            print("âŒ è·å–å®æ—¶è¡Œæƒ…å¤±è´¥ï¼Œå°†è·³è¿‡é‡æ¯”ç­›é€‰å’Œä»·æ ¼æ˜¾ç¤º")

        valid_stocks = []
        stock_dict = {s['ä»£ç ']: s for s in all_stocks}
        for symbol, tick_df in tick_data_results.items():
            if symbol in historical_metrics:
                valid_stocks.append((
                    stock_dict[symbol],
                    tick_df,
                    historical_metrics[symbol],
                    fund_flow_data.get(symbol),
                    volume_ratios.get(symbol, 0),
                    current_prices.get(symbol, 0),
                    change_pcts.get(symbol, 0),
                    turnover_rates.get(symbol, 0)
                ))
            else:
                print(f"  âš ï¸ {symbol} ({stock_dict.get(symbol, {}).get('è‚¡ç¥¨åç§°', '')}) ç¼ºå°‘å¿…è¦çš„å†å²è¡Œæƒ…æ•°æ®ï¼Œè·³è¿‡")

        if not valid_stocks: return []

        print("\nğŸ“Š æ­¥éª¤ 3/3: æ‰¹é‡åˆ†æå¹¶è®¡ç®—å¾—åˆ†...")
        analysis_results = {}
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            futures = [executor.submit(self.analyze_stock_worker, s, df, market_performance, hm, ffd, vr, cp, chg, tr)
                       for s, df, hm, ffd, vr, cp, chg, tr in valid_stocks]
            for f in as_completed(futures):
                try:
                    res = f.result()
                    if res:
                        symbol, result = res
                        analysis_results[symbol] = result
                except Exception as e:
                    print(f"  âš ï¸ åˆ†æä»»åŠ¡å¼‚å¸¸: {e}")

        sorted_stocks = sorted(analysis_results.items(), key=lambda x: x[1]['score'], reverse=True)

        print("\nğŸ”¬ æœ€ç»ˆç»“æœåˆ—è¡¨ (ä»…æ’åºï¼Œæ— ç­›é€‰)...")
        final_stocks = list(sorted_stocks)

        total_time = time.time() - total_start
        print(f"\nâœ… åˆ†æå®Œæˆï¼Œæœ€ç»ˆç”Ÿæˆ {len(final_stocks)} åªè‚¡ç¥¨çš„æ’åºåˆ—è¡¨ï¼Œæ€»è€—æ—¶: {total_time:.2f}ç§’")

        # æ‰“å°æ€§èƒ½ç»Ÿè®¡
        print("\nâ±ï¸ æ€§èƒ½ç»Ÿè®¡:")
        for task, time_spent in sorted(self.perf_counters.items(), key=lambda x: x[1], reverse=True)[:10]:
            print(f"  - {task}: {time_spent:.2f}ç§’")

        return final_stocks

    def send_dingtalk_message(self, top_stocks):
        """å‘é€é’‰é’‰æ¶ˆæ¯"""
        webhook_url = "https://oapi.dingtalk.com/robot/send?access_token=ae055118615b242c6fe43fc3273a228f316209f707d07e7ce39fc83f4270ed82"
        secret = "SECf2b2861525388e240846ad1e2beb3b93d3b5f0d2e6634e43176b593f050e77da"

        stocks_to_send = top_stocks[:30]
        if not stocks_to_send: return False

        text = f"# ğŸ“ˆ é‡åŒ–åˆ†ææŠ¥å‘Š V8.0 - {datetime.now().strftime('%Y-%m-%d %H:%M')}\n\n"
        text += f"## ğŸ† è‚¡ç¥¨è¯„åˆ†æ’åº (Top {len(stocks_to_send)})\n\n"

        for i, (symbol, data) in enumerate(stocks_to_send, 1):
            model_tag = f"({data['model_version']})"

            change_pct = data.get('change_pct', 0)
            price_str = f"Â¥{data.get('current_price', 0):.2f}"
            change_str = f"{'ğŸ“ˆ' if change_pct > 0 else 'ğŸ“‰'} {change_pct:.2f}%"
            turnover_str = f"æ¢æ‰‹: {data.get('turnover_rate', 0):.2f}%"
            title_line = f"### {i}. {data['name']} ({symbol})\n- **{price_str}** ({change_str}) | {turnover_str}\n"

            score_line = f"- **å¾—åˆ†**: **{data['score']:.2f}** {model_tag}\n"

            z_score_line = f"- **èµ„é‡‘æµå¼ºåº¦ (Z-score)**: ä¸»åŠ› **{data['fund_flow_z_score']:.2f}** / è¶…å¤§å• **{data['super_flow_z_score']:.2f}**\n"

            text += f"""{title_line}{score_line}{z_score_line}- **é‡æ¯”**: {data.get('volume_ratio', 'N/A'):.2f}
- **ä¹°å–å‹åŠ›æ¯”**: {data.get('pressure_ratio', 1.0):.2f}
- **å¤§å•ä¹°å…¥å æ¯”**: {data.get('large_buy_ratio', 0):.2%} vs å–å‡º {data.get('large_sell_ratio', 0):.2%}
- **æ—¥å†…æ¶¨è·Œ**: {data['intraday_change']:.2f}% (è¶…é¢: {data['excess_return']:.2f}%)
- **å‡€ä¹°å…¥å æ¯” (vs ADV20)**: {data['net_buy_adv_ratio']:.2%}
- **åŠ¨é‡æ¯”ç‡**: {data['momentum_ratio']:.2f} / æ”¶ç›˜: {data['closing_ratio']:.2f}
- **æŠ€æœ¯æŒ‡æ ‡**: RSI {data.get('rsi', 0):.1f} | Beta {data.get('beta', 0):.2f}
- **å¯¹å€’å«Œç–‘**: {data.get('wash_trade_ratio', 0):.2%}
"""

        message = {"msgtype": "markdown", "markdown": {"title": "é‡åŒ–åˆ†ææŠ¥å‘Š V8.0", "text": text}}
        timestamp = str(round(time.time() * 1000))
        string_to_sign = f"{timestamp}\n{secret}"
        hmac_code = hmac.new(secret.encode('utf-8'), string_to_sign.encode('utf-8'), digestmod=hashlib.sha256).digest()
        sign = base64.b64encode(hmac_code).decode('utf-8')
        full_webhook_url = f"{webhook_url}&timestamp={timestamp}&sign={sign}"

        try:
            response = self.session.post(full_webhook_url, json=message, timeout=10)
            if response.status_code == 200 and response.json().get("errcode") == 0:
                print("âœ… é’‰é’‰æ¶ˆæ¯å‘é€æˆåŠŸï¼")
                return True
            else:
                print(f"âŒ é’‰é’‰æ¶ˆæ¯å‘é€å¤±è´¥: {response.text}")
                return False
        except Exception as e:
            print(f"âŒ å‘é€é’‰é’‰æ¶ˆæ¯æ—¶å‡ºé”™: {e}")
            return False

    def run_analysis(self):
        """è¿è¡Œå®Œæ•´åˆ†ææµç¨‹"""
        print("ğŸ” é‡åŒ–åˆ†æç³»ç»Ÿ V8.0 - å¼€å§‹åˆ†æçƒ­é—¨è‚¡ç¥¨")
        try:
            top_stocks = self.analyze_stocks()

            if not top_stocks:
                print("ğŸ¤· æ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨å¯å‘é€")
                return

            self.send_dingtalk_message(top_stocks)
        except Exception as e:
            print(f"âŒ åˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            traceback.print_exc()



def main():
    analyzer = QuantAnalysis()
    analyzer.run_analysis()


if __name__ == "__main__":
    main()
